services:
  ollama:
      image: ollama/ollama:${OLLAMA_DOCKER_TAG-latest}
      container_name: ollama
      volumes:
        - ollama:/root/.ollama
      pull_policy: always
      tty: true
      restart: unless-stopped
      networks:
        - internal

  open-webui:
    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    networks:
      - internal
    restart: unless-stopped
    environment:
      # General
      ENV: production
      DEFAULT_USER_ROLE: pending
      ENABLE_SIGNUP: True
      RESET_CONFIG_ON_START: ${RESET_CONFIG_ON_START-false}
      # SSO
      WEBUI_AUTH_TRUSTED_EMAIL_HEADER: X-AUTHENTIK-EMAIL
      # Model Connections
      OLLAMA_BASE_URL: http://ollama:11434
      OPENAI_API_BASE_URL: https://api.deepinfra.com/v1/openai
      OPENAI_API_KEY: ${OPENAI_API_KEY?Variable not set}
      WEBUI_SECRET_KEY: ${WEBUI_SECRET_KEY?Variable not set}
      ENABLE_COMMUNITY_SHARING: false
      # RAG
      RAG_TOP_K: 10
      ENABLE_RAG_HYBRID_SEARCH: true
      ENABLE_RAG_WEB_SEARCH: true
      RAG_WEB_SEARCH_ENGINE: duckduckgo
      RAG_WEB_SEARCH_RESULT_COUNT: 5
      ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION: true
      PDF_EXTRACT_IMAGES: true
      RAG_EMBEDDING_ENGINE: ollama
      RAG_EMBEDDING_MODEL: nomic-embed-text:latestd
      RAG_RERANKING_MODEL: BAAI/bge-reranker-base
      RAG_TEMPLATE: |
        **Generate Response to User Query**
        **Step 1: Parse Context Information**
        Extract and utilize relevant knowledge from the provided context within `<context></context>` XML tags.
        **Step 2: Analyze User Query**
        Carefully read and comprehend the user's query, pinpointing the key concepts, entities, and intent behind the question.
        **Step 3: Determine Response**
        If the answer to the user's query can be directly inferred from the context information, provide a concise and accurate response in the same language as the user's query.
        **Step 4: Handle Uncertainty**
        If the answer is not clear, ask the user for clarification to ensure an accurate response.
        **Step 5: Avoid Context Attribution**
        When formulating your response, do not indicate that the information was derived from the context.
        **Step 6: Respond in User's Language**
        Maintain consistency by ensuring the response is in the same language as the user's query.
        **Step 7: Provide Response**
        Generate a clear, concise, and informative response to the user's query, adhering to the guidelines outlined above.
        User Query: [query]
        <context>
        [context]
        </context>
  flowise:
    image: flowiseai/flowise
    container_name: flowise
    restart: unless-stopped
    networks:
      - internal
    environment:
      DISABLE_FLOWISE_TELEMETRY: true
      PORT: 3000
      DATABASE_PATH: /root/.flowise
      APIKEY_PATH: /root/.flowise
      SECRETKEY_PATH: /root/.flowise
      LOG_PATH: /root/.flowise/logs
      BLOB_STORAGE_PATH: /root/.flowise/storage
    volumes:
      - flowise:/root/.flowise


volumes:
  open-webui:
  ollama:
  flowise:

networks:
  internal:
    name: internal
    external: true